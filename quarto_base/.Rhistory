paste(collapse = "\n")
}else{
body <- body %>%
paste0(collapse = "")
}
author <- page_home %>% html_element("#isShowDocAuthor") %>% html_text2()
out <- c(title,source_plus_time,body,author,link)
return(out)
}
test_out <- page_extract(scrape_list[1])
test == 0 | identical(test,character(0))==T
test
page_extract <- function(link){
page_home <- read_html(link)
title <- page_home %>%
html_element(".newsTop") %>%
html_element("h1") %>%
html_text2()
source_plus_time <- page_home %>% html_elements(".sT_left") %>% html_text2()
body <- page_home %>%
html_element(".TRS_Editor") %>%
html_elements("p") %>%
html_text2()
# write check for body problems
test <- str_length(body)
if(test == 0 | identical(test,character(0))==T | identical(test,integer(0))==T){
body <- page_home %>% html_element(".news_content_style") %>%
html_elements("p") %>%
html_text2() %>%
paste(collapse = "\n")
}else{
body <- body %>%
paste0(collapse = "")
}
author <- page_home %>% html_element("#isShowDocAuthor") %>% html_text2()
out <- c(title,source_plus_time,body,author,link)
return(out)
}
test_out <- page_extract(scrape_list[1])
identical(test,character(0))
identical(test,logical(0))
test
identical(test,integer(0))
page_extract <- function(link){
page_home <- read_html(link)
title <- page_home %>%
html_element(".newsTop") %>%
html_element("h1") %>%
html_text2()
source_plus_time <- page_home %>% html_elements(".sT_left") %>% html_text2()
body <- page_home %>%
html_element(".TRS_Editor") %>%
html_elements("p") %>%
html_text2()
# write check for body problems
test <- str_length(body)
if(identical(test,integer(0))==T){
body <- page_home %>% html_element(".news_content_style") %>%
html_elements("p") %>%
html_text2() %>%
paste(collapse = "\n")
}else{
body <- body %>%
paste0(collapse = "")
}
author <- page_home %>% html_element("#isShowDocAuthor") %>% html_text2()
out <- c(title,source_plus_time,body,author,link)
return(out)
}
test_out <- page_extract(scrape_list[1])
page_home <- read_html(test_link)
page_home %>%
html_element(".newsTop") %>%
html_element("h1") %>%
html_text2()
page_home %>% html_elements(".sT_left") %>% html_text2()
body <- page_home %>%
html_element(".TRS_Editor") %>%
html_elements("p") %>%
html_text2()
body
test <- str_length(body)
test
identical(test,integer(0))
body <- body %>%
paste0(collapse = "")
body
page_home %>% html_element("#isShowDocAuthor") %>% html_text2()
out <- c(title,source_plus_time,body,author,link)
page_extract <- function(link){
page_home <- read_html(link)
title <- page_home %>%
html_element(".newsTop") %>%
html_element("h1") %>%
html_text2()
source_plus_time <- page_home %>% html_elements(".sT_left") %>% html_text2()
body <- page_home %>%
html_element(".TRS_Editor") %>%
html_elements("p") %>%
html_text2()
# write check for body problems
test <- str_length(body)
if(identical(test,integer(0))==T){
body <- page_home %>% html_element(".news_content_style") %>%
html_elements("p") %>%
html_text2() %>%
paste(collapse = "")
}else{
body <- body %>%
paste0(collapse = "\n")
}
author <- page_home %>% html_element("#isShowDocAuthor") %>% html_text2()
out <- c(title,source_plus_time,body,author,link)
return(out)
}
test_out <- page_extract(test_link)
test_out
for(i in 1:length(scrape_list)){
scrape_tmp <- sample(scrape_list) #scrambles order
tmp <- page_extract(scrape_tmp[i])
print(scrape_tmp[i])
final_out$V1[i] <- tmp[1]
final_out$V2[i] <- tmp[2]
final_out$V3[i] <- tmp[3]
final_out$V4[i] <- tmp[4]
final_out$V5[i] <- tmp[5]
Sys.sleep(8)
print(paste("Scraped ",as.character(i), " out of ",length(scrape_list),
" or ",as.character(round(i/length(scrape_list)*100,digits=0)),"% done.")
)
}
for(i in 1:length(scrape_list)){
scrape_tmp <- sample(scrape_list) #scrambles order
tmp <- page_extract(scrape_tmp[i])
print(scrape_tmp[i])
final_out$V1[i] <- tmp[1]
final_out$V2[i] <- tmp[2]
final_out$V3[i] <- tmp[3]
final_out$V4[i] <- tmp[4]
final_out$V5[i] <- tmp[5]
Sys.sleep(8)
print(paste("Scraped ",as.character(i)))
}
for(i in 1:length(scrape_list)){
#scrape_tmp <- sample(scrape_list) #scrambles order
tmp <- page_extract(scrape_list[i])
print(scrape_tmp[i])
final_out$V1[i] <- tmp[1]
final_out$V2[i] <- tmp[2]
final_out$V3[i] <- tmp[3]
final_out$V4[i] <- tmp[4]
final_out$V5[i] <- tmp[5]
Sys.sleep(8)
print(paste("Scraped ",as.character(i)))
}
tmp <- page_extract(scrape_list[1])
scrape_list[1]
page_extract <- function(link){
page_home <- read_html(link)
title <- page_home %>%
html_element(".newsTop") %>%
html_element("h1") %>%
html_text2()
source_plus_time <- page_home %>% html_elements(".sT_left") %>% html_text2()
body <- page_home %>%
html_element(".TRS_Editor") %>%
html_elements("p") %>%
html_text2()
# write check for body problems
test <- str_length(body)
if(identical(test,integer(0))==T){
body <- page_home %>% html_element(".news_content_style") %>%
html_elements("p") %>%
html_text2() %>%
paste0(collapse = "")
}else{
body <- body %>%
paste0(collapse = "\n")
}
author <- page_home %>% html_element("#isShowDocAuthor") %>% html_text2()
out <- c(title,source_plus_time,body,author,link)
return(out)
}
tmp <- page_extract(scrape_list[1])
tmp
for(i in 1:length(scrape_list)){
#scrape_tmp <- sample(scrape_list) #scrambles order
tmp <- page_extract(scrape_list[i])
print(scrape_list[i])
final_out$V1[i] <- tmp[1]
final_out$V2[i] <- tmp[2]
final_out$V3[i] <- tmp[3]
final_out$V4[i] <- tmp[4]
final_out$V5[i] <- tmp[5]
Sys.sleep(8)
print(paste("Scraped ",as.character(i)))
}
for(i in 1:length(scrape_list)){
#scrape_tmp <- sample(scrape_list) #scrambles order
tmp <- page_extract(scrape_list[i])
print(scrape_list[i])
final_out$V1[i] <- tmp[1]
final_out$V2[i] <- tmp[2]
final_out$V3[i] <- tmp[3]
final_out$V4[i] <- tmp[4]
final_out$V5[i] <- tmp[5]
Sys.sleep(8)
print(paste("Scraped ",as.character(i),sep = " "))
}
View(final_out)
write_csv(final_out,"center_fazhi_ducha_yifazhiguo_news_april9_25.csv")
library(tidyverse)
library(rvest)
test_link <- "https://sft.guizhou.gov.cn/ywgz_97/fzdc/202410/t20241014_85934601.html"
home <- read_html("https://sft.guizhou.gov.cn/ywgz_97/fzdc/202410/t20241014_85934601.html")
home %>% html_element(".toolbar") %>% html_elements("span") %>% html_text2()
home %>% html_element(".toolbar") %>% html_elements("span")
home %>% html_element(".toolbar") %>% html_elements("span") %>% slice_head(3)
home %>% html_element(".toolbar") %>% html_elements("span") %>% slice_head(n=3)
toolbar_eles <- home %>% html_element(".toolbar") %>% html_elements("span")
toolbar_eles2 <- toolbar_eles[1:3]
toolbar_eles2
toolbar_eles2[[1]]
print(toolbar_eles2[[1]])
print(toolbar_eles2[[1]][1])
print(toolbar_eles2[[1]][2])
print(toolbar_eles2[[1]][3])
print(toolbar_eles2[[1]][4])
toolbar_eles2 %>% html_text()
install.packages("xml2")
library(xml2)
xml_remove(xml_find_all(toolbar_eles2,".//script"))
xml_remove(xml_find_all(toolbar_eles2[1],".//script"))
toolbar_eles2[1]
View(toolbar_eles2)
html <- read_html('
<div>
<span>This is the first<span><script>console.log("junk")</script></span></span>
<span>This is the second<script>console.log("irrelevant")</script></span>
<span>This is the third one</span>
</div>
')
span_nodes <- html %>% html_elements("span")
library(tidyverse)
span_nodes <- html %>% html_elements("span")
library(rvest)
toolbar_eles2[1]
home <- read_html("https://sft.guizhou.gov.cn/ywgz_97/fzdc/202410/t20241014_85934601.html")
toolbar_eles <- home %>% html_element(".toolbar") %>% html_elements("span")
toolbar_eles2 <- toolbar_eles[1:3]
library(xml2)
xml_remove(xml_find_all(toolbar_eles2[1],".//script"))
html_text2(toolbar_eles2[1])
toolbar_eles2[1]
toolbar_eles2[2]
ex <- '<span>
<script type="text/javascript">
var zz = '厅警务督察总队';
ex <- "<span>
<script type="text/javascript">
ex <- "<span> <script type="text/javascript"> var zz = '厅警务督察总队'; if (zz != '') {document.write('作者：' + zz + '&emsp;');} else {document.write('作者：贵州省司法厅&emsp;');}</script>作者：厅警务督察总队 </span>"
ex <- ""<span> <script type="text/javascript"> var zz = '厅警务督察总队'; if (zz != '') {document.write('作者：' + zz + '&emsp;');} else {document.write('作者：贵州省司法厅&emsp;');}</script>作者：厅警务督察总队 </span>""
ex <- <span> <script type='text/javascript'> var zz = '厅警务督察总队'; if (zz != '') {document.write('作者：' + zz + '&emsp;');} else {document.write('作者：贵州省司法厅&emsp;');}</script>作者：厅警务督察总队 </span>"
ex <- "<span> <script type='text/javascript'> var zz = '厅警务督察总队'; if (zz != '') {document.write('作者：' + zz + '&emsp;');} else {document.write('作者：贵州省司法厅&emsp;');}</script>作者：厅警务督察总队 </span>"
ex
toolbar_eles2 <- toolbar_eles[1:3]
toolbar_eles2[1] %>% html_text2()
toolbar_eles <- home %>% html_element(".toolbar") %>% html_elements("span")
toolbar_eles
home <- read_html("https://sft.guizhou.gov.cn/ywgz_97/fzdc/202410/t20241014_85934601.html")
toolbar_eles <- home %>% html_element(".toolbar") %>% html_elements("span")
toolbar_eles[1]
print(toolbar_eles[1])
x <- print(toolbar_eles[1])
view(x)
minimal_html(toolbar_eles[1])
minimal_html(toolbar_eles[1])[2]
minimal_html(toolbar_eles[1])
html_text2(toolbar_eles[1])
html_text2(toolbar_eles[3])
"
<span>
<script type="text/javascript">
toolbar_eles[3]
write_file(toolbar_eles2[3],"test.txt")
write_file(unlist(toolbar_eles2[3]),"test.txt")
print(toolbar_eles2[3])
x <- toolbar_eles2[3]
View(x)
x
home <- read_html("https://sft.guizhou.gov.cn/ywgz_97/fzdc/202410/t20241014_85934601.html")
toolbar_eles <- home %>% html_element(".toolbar") %>% html_elements("span") %>% html_elements("script")
view(toolbar_eles)
View(toolbar_eles)
toolbar_eles <- home %>% html_element(".toolbar") %>% html_elements("span") %>% html_elements("script[type='text/javascript']")
toolbar_eles_text <- home %>% html_element(".toolbar") %>% html_elements("span") %>% html_elements("script[type='text/javascript']") %>% html_text2()
View(toolbar_eles2)
View(toolbar_eles)
toolbar_eles_text
extract_source <- function(text_input){
match <- regmatches(text_input, regexpr("var wzly\\s*=\\s*'(.*?)'|var wzly\\s*\"(.*?)\"",text_input,perl=T))
if(length(match)==0){}
}
extract_source <- function(text_input){
match <- regmatches(text_input, regexpr("var wzly\\s*=\\s*'(.*?)'|var wzly\\s*\"(.*?)\"",text_input,perl=T))
if(length(match)==0){
return(NA)
}
}
extract_source(toolbar_eles_text[1])
extract_source(toolbar_eles_text[2])
extract_source <- function(text_input){
match <- regmatches(text_input, regexpr("var wzly\\s*=\\s*'(.*?)'|var wzly\\s*\"(.*?)\"",text_input,perl=T))
if(length(match)==0){
return(NA)
}else{}
}
extract_source <- function(text_input){
match <- regmatches(text_input, regexpr("var wzly\\s*=\\s*'(.*?)'|var wzly\\s*\"(.*?)\"",text_input,perl=T))
if(length(match)==0){
return(NA)
}else{
return(match)
}
}
extract_source(toolbar_eles_text[2])
extract_source <- function(text_input){
match <- regmatches(text_input, regexpr("var wzly\\s*=\\s*'(.*?)'|var wzly\\s*\"(.*?)\"",text_input,perl=T))
if(length(match)==0){
return(NA)
}
#extract value
wzly_val = sub("var wzly\\s*=\\s*['\"](.*?)['\"].*", "\\1", match)
#determine author
if(wzly_val != ""){
return(paste0("来源: ",wzly_val))
} else {
return("来源：贵州省司法厅")
}
}
extract_source(toolbar_eles_text[2])
extract_author <- function(script_text) {
match <- regmatches(script_text, regexpr("var zz\\s*=\\s*'(.?)'|var zz\\s=\\s*\"(.*?)\"", script_text, perl = TRUE))
# Handle match
if (length(match) == 0) {
return(NA)
}
# Extract zz value (either from single or double quotes)
zz_val <- sub("var zz\\s*=\\s*['\"](.?)['\"].", "\\1", match)
# Determine author
if (zz_val != "") {
return(paste0("作者：", zz_val))
} else {
return("作者：贵州省司法厅")
}
}
extract_author(toolbar_eles_text[3])
extract_author(toolbar_eles_text[2])
extract_author(toolbar_eles_text[1])
extract_author(toolbar_eles_text[3])
toolbar_eles_text[3]
extract_author <- function(script_text) {
# Use regex to extract zz value in single or double quotes
match <- regmatches(script_text, regexpr("var zz\\s*=\\s*['\"](.*?)['\"]", script_text, perl = TRUE))
if (length(match) == 0) {
return(NA)  # nothing matched
}
# Extract just the value of zz
zz_val <- sub("var zz\\s*=\\s*['\"](.*?)['\"]", "\\1", match)
# Determine the author based on whether zz is empty
if (zz_val != "") {
return(paste0("作者：", zz_val))
} else {
return("作者：贵州省司法厅")
}
}
extract_author(toolbar_eles_text[3])
extract_source(toolbar_eles_text[2])
toolbar_eles_text[1]
extract_date <- function(input_text){
match <- regmatches(text_input, regexpr("var pubdata\\s*=\\s*'(.*?)'|var pubdata\\s*\"(.*?)\"",text_input,perl=T))
if(length(match)==0){
return(NA)
}
#extract value
pubdata_val = sub("var pubdata\\s*=\\s*['\"](.*?)['\"].*", "\\1", match)
if(pubdata_val != ""){
return(paste0("日期: ",pubdata_val))
} else {
return(NA)
}}
extract_date(toolbar_eles_text[1])
extract_date <- function(text_input){
match <- regmatches(text_input, regexpr("var pubdata\\s*=\\s*'(.*?)'|var pubdata\\s*\"(.*?)\"",text_input,perl=T))
if(length(match)==0){
return(NA)
}
#extract value
pubdata_val = sub("var pubdata\\s*=\\s*['\"](.*?)['\"].*", "\\1", match)
if(pubdata_val != ""){
return(paste0("日期: ",pubdata_val))
} else {
return(NA)
}}
extract_date(toolbar_eles_text[1])
out <- c(extract_date(toolbar_eles_text[1]),
extract_source(toolbar_eles_text[2]),
extract_author(toolbar_eles_text[3])
)
out
newslink <- ""
newslink <- "https://sft.guizhou.gov.cn/ywgz_97/fzdc/201904/t20190422_2427023.html"
extract_author <- function(script_text) {
# Use regex to extract zz value in single or double quotes
match <- regmatches(script_text, regexpr("var zz\\s*=\\s*['\"](.*?)['\"]", script_text, perl = TRUE))
if (length(match) == 0) {
return(NA)  # nothing matched
}
# Extract just the value of zz
zz_val <- sub("var zz\\s*=\\s*['\"](.*?)['\"]", "\\1", match)
# Determine the author based on whether zz is empty
if (zz_val != "") {
return(paste0("作者：", zz_val))
} else {
return("作者：贵州省司法厅")
}
}
extract_source <- function(text_input){
match <- regmatches(text_input, regexpr("var wzly\\s*=\\s*'(.*?)'|var wzly\\s*\"(.*?)\"",text_input,perl=T))
if(length(match)==0){
return(NA)
}
#extract value
wzly_val = sub("var wzly\\s*=\\s*['\"](.*?)['\"].*", "\\1", match)
#determine author
if(wzly_val != ""){
return(paste0("来源: ",wzly_val))
} else {
return("来源：贵州省司法厅")
}}
extract_date <- function(text_input){
match <- regmatches(text_input, regexpr("var pubdata\\s*=\\s*'(.*?)'|var pubdata\\s*\"(.*?)\"",text_input,perl=T))
if(length(match)==0){
return(NA)
}
#extract value
pubdata_val = sub("var pubdata\\s*=\\s*['\"](.*?)['\"].*", "\\1", match)
if(pubdata_val != ""){
return(paste0("日期: ",pubdata_val))
} else {
return(NA)
}}
home <- read_html(newslink)
toolbar_eles_text <- home %>%
html_element(".toolbar") %>%
html_elements("span") %>%
html_elements("script[type='text/javascript']") %>%
html_text2()
out <- c(extract_date(toolbar_eles_text[1]),
extract_source(toolbar_eles_text[2]),
extract_author(toolbar_eles_text[3])
)
out
#### helper functions
extract_author <- function(script_text) {
# Use regex to extract zz value in single or double quotes
match <- regmatches(script_text, regexpr("var zz\\s*=\\s*['\"](.*?)['\"]", script_text, perl = TRUE))
if (length(match) == 0) {
return(NA)  # nothing matched
}
# Extract just the value of zz
zz_val <- sub("var zz\\s*=\\s*['\"](.*?)['\"]", "\\1", match)
# Determine the author based on whether zz is empty
if (zz_val != "") {
return(paste0("作者：", zz_val))
} else {
return("作者：贵州省司法厅")
}
}
extract_source <- function(text_input){
match <- regmatches(text_input, regexpr("var wzly\\s*=\\s*'(.*?)'|var wzly\\s*\"(.*?)\"",text_input,perl=T))
if(length(match)==0){
return(NA)}
#extract value
wzly_val = sub("var wzly\\s*=\\s*['\"](.*?)['\"].*", "\\1", match)
#determine author
if(wzly_val != ""){
return(paste0("来源: ",wzly_val))
} else {
return("来源：贵州省司法厅")
}}
extract_date <- function(text_input){
match <- regmatches(text_input, regexpr("var pubdata\\s*=\\s*'(.*?)'|var pubdata\\s*\"(.*?)\"",text_input,perl=T))
if(length(match)==0){
return(NA)}
#extract value
pubdata_val = sub("var pubdata\\s*=\\s*['\"](.*?)['\"].*", "\\1", match)
if(pubdata_val != ""){
return(paste0("日期: ",pubdata_val))
} else {
return(NA)}}
home <- read_html(newslink)
toolbar_eles_text <- home %>%
html_element(".toolbar") %>%
html_elements("span") %>%
html_elements("script[type='text/javascript']") %>%
html_text2()
out <- c(extract_date(toolbar_eles_text[1]),
extract_source(toolbar_eles_text[2]),
extract_author(toolbar_eles_text[3])
)
out
